{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc0f883-cf25-4867-a618-00bc86b48694",
   "metadata": {},
   "source": [
    "# 01 - DISTILGPT2\n",
    "\n",
    "We will get started by open and exploring distilgpt2 model: https://huggingface.co/distilbert/distilgpt2\n",
    "This model is a distilation of OpenAI's GPT-2 but smaller (6 transformers blocks and 82M parametres instead of 12 transformers blocks and 124M parametetrs from GPT-2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f20d7f3-4dc0-41b8-8947-6b384e543691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e937fcf-ffe2-45d9-abc8-c98de06a13b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# login to Hugging Face, login token is in an environment variable\n",
    "login(token=os.getenv(\"HUGGINGFACE_HUB_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baebb7d-b730-4d89-80f7-f59b27e099cd",
   "metadata": {},
   "source": [
    "## Load model from hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ef82cef-bb5c-425b-8c1a-fda041f0e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\", cache_dir=r\"D:\\hf_files\")  \n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\", cache_dir=r\"D:\\hf_files\")"
   ]
  },
  {
   "attachments": {
    "cac6edcf-ea18-49dc-8fb8-7a25ee50fa86.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "79f31cd6-7749-4d85-ae1f-29f52d01ecad",
   "metadata": {},
   "source": [
    "## Explore tokenizer\n",
    "The LLMs don't break words in syllables neither letters. It has its own form of breaking text, each individual piece of the split text is a token. Different models have different token system. A token can be a single word, a piece of a word, a single character or even more then one work. A cool way to explore how tokenized texts is OpenAI's tokenizer webapp: https://platform.openai.com/tokenizer . They create it to help people visualize the tokenization output. ![image.png](attachment:cac6edcf-ea18-49dc-8fb8-7a25ee50fa86.png) <br> The token system is create during model training. Each token has its own ID. The very first step when using a LLM is transform text in tokens (encode). The very last step when using a LLM is converst its response in tokens back to text (decode)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24dd5e9a-b866-4a15-a747-874aaa4a15b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 2011, 1545, 0]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# tokenize string to see output\n",
    "messages = \"Hello, My friend!\" \n",
    "tokens = tokenizer.encode(messages)  \n",
    "print(tokens)           # list of token IDs  \n",
    "print(len(tokens))      # number of tokens  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf378cb-16d1-411e-a479-845994f20aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, My friend!\n"
     ]
    }
   ],
   "source": [
    "#retunr token list back to string\n",
    "decoded_text = tokenizer.decode(tokens)  \n",
    "print(decoded_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a5f7e3d-6ac4-4448-a767-c00f834751e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 23748, 11, 2011, 1545, 0]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# note that \"Hello\" and \"hello\" are differente tokens\n",
    "messages = \"Hello hello, My friend!\" \n",
    "tokens = tokenizer.encode(messages)  \n",
    "print(tokens)           # list of token IDs  \n",
    "print(len(tokens))      # number of tokens  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bd49739-0472-4222-a944-ff867593af8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31373, 23748, 11, 2011, 1545, 0]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# even with both words starting with lowercase letter they are different tokens\n",
    "# one is start of string, another is preceeded by whitespace \n",
    "messages = \"hello hello, My friend!\" \n",
    "tokens = tokenizer.encode(messages)  \n",
    "print(tokens)           # list of token IDs  \n",
    "print(len(tokens))      # number of tokens  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8755826-bfa6-45ae-80ea-8f801e346d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23748, 23748, 11, 2011, 1545, 0]\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# even with both words starting with lowercase letter they are different tokens\n",
    "messages = \" hello hello, My friend!\" \n",
    "tokens = tokenizer.encode(messages)  \n",
    "print(tokens)           # list of token IDs  \n",
    "print(len(tokens))      # number of tokens  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca13d48-9288-44dd-b79d-f00879f4b247",
   "metadata": {},
   "source": [
    "## Explore the model\n",
    "LLMs are made of several layers with different roles. Let's understand all these layer and its roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69447a61-b8d2-4da0-b68d-9fdde041fee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-5): 6 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D(nf=2304, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=768)\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=3072, nx=768)\n",
      "          (c_proj): Conv1D(nf=768, nx=3072)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# see model's details\n",
    "print(model)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc58ab3-5b4e-4d8d-96c7-799ee70e397a",
   "metadata": {},
   "source": [
    "### wte (Word Token Embedding)\n",
    "Each token has its own embedding vector. These embedding vectors were created during training. <br> The details provided for this fase are: <br>`(wte): Embedding(50257, 768)` <br> From this details we can learn: <br> - there are 50257 tokens (all text is mapped to one of this tokens)<br> - the embedding vector have dimension 768 (embedding vectors have fixed size)<br> Each token has a embedding vector (dense) of dimension 768. During this layer a lookup table is used and the embedding vector of each input token is recovered. The output is the embedding matrix, where each line represents one input token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39ad50ae-9061-4db1-9d46-270c545a5897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0653, -0.1096,  0.1105,  ..., -0.0884,  0.1287,  0.0113],\n",
      "         [ 0.0653, -0.1096,  0.1105,  ..., -0.0884,  0.1287,  0.0113],\n",
      "         [ 0.0086, -0.0009,  0.0056,  ...,  0.0484, -0.0737, -0.0636],\n",
      "         [ 0.0714,  0.1300,  0.1132,  ...,  0.1220, -0.0033,  0.0546],\n",
      "         [-0.0640, -0.1471,  0.0998,  ..., -0.0914,  0.1967,  0.1006],\n",
      "         [-0.1445, -0.0455,  0.0042,  ..., -0.1523,  0.0184,  0.0991]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# enconde again now generating a Tensor as output\n",
    "tokens = tokenizer(messages,  return_tensors=\"pt\") \n",
    "\n",
    "# visualize the embedding matrix\n",
    "# notice that repeated tokens recovery same embedding\n",
    "token_embeds = model.transformer.wte(tokens[\"input_ids\"])  # (batch, seq_len, 768)  \n",
    "print(token_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0930cc-a995-46b6-83cd-fd02893ea7f7",
   "metadata": {},
   "source": [
    "### wpe (Word position Embedding)\n",
    "The token position in the string is important. So, this layer adds this is about this information. Each position in the string have an embedding vector.  <br> The details provided for this fase are: <br>`(wpe): Embedding(1024, 768)` <br> From this details we can learn: <br> - the maximum token window size is 1024<br> - the embedding vector also have dimension 768 (embedding vectors have fixed size)<br> During this layer a lookup table is used and the embedding vector of each position is recovered. The output is the embedding matrix, where each line represents one position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5557901e-e619-4a6d-9d8f-5ad09d223acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.8821e-02, -1.9742e-01,  4.0267e-03,  ..., -4.3044e-02,\n",
      "           2.8267e-02,  5.4490e-02],\n",
      "         [ 2.3959e-02, -5.3792e-02, -9.4879e-02,  ...,  3.4170e-02,\n",
      "           1.0172e-02, -1.5573e-04],\n",
      "         [ 4.2161e-03, -8.4764e-02,  5.4515e-02,  ...,  1.9745e-02,\n",
      "           1.9325e-02, -2.1424e-02],\n",
      "         [-2.8337e-04, -7.3803e-02,  1.0553e-01,  ...,  1.0157e-02,\n",
      "           1.7659e-02, -7.0854e-03],\n",
      "         [ 7.6374e-03, -2.5090e-02,  1.2696e-01,  ...,  8.4643e-03,\n",
      "           9.8542e-03, -7.0117e-03],\n",
      "         [ 9.6023e-03, -3.3885e-02,  1.3123e-01,  ...,  5.8940e-03,\n",
      "           7.1222e-03, -7.4742e-03]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# see embeddings of positions\n",
    "position_ids = torch.arange(0, tokens['input_ids'].size(1)).unsqueeze(0)\n",
    "\n",
    "pos_embeds   = model.transformer.wpe(position_ids)\n",
    "print(pos_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ceb2b0-7d58-4f82-a5f0-2c1ce14fe18e",
   "metadata": {},
   "source": [
    "### wte + wpe\n",
    "A linear sum between wte and wpe output is performed now. Both are matrix with same size, the number of row is the number of tokens in the input and the number of columns is the embedding vector size. The output is also a matrix with same dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e99ffe6-fbaf-4291-b77e-e33d6b0a9546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0465, -0.3070,  0.1146,  ..., -0.1315,  0.1570,  0.0658],\n",
      "         [ 0.0893, -0.1634,  0.0157,  ..., -0.0543,  0.1389,  0.0112],\n",
      "         [ 0.0128, -0.0856,  0.0601,  ...,  0.0681, -0.0544, -0.0850],\n",
      "         [ 0.0711,  0.0562,  0.2187,  ...,  0.1322,  0.0143,  0.0475],\n",
      "         [-0.0564, -0.1722,  0.2268,  ..., -0.0830,  0.2066,  0.0936],\n",
      "         [-0.1349, -0.0794,  0.1355,  ..., -0.1464,  0.0255,  0.0916]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeds + pos_embeds\n",
    "print(input_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb55635-4d23-4d89-a60e-01c3303adbf3",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "Dropout is a regularization technique used to prevent overfitting by randomly setting a fraction of the input elements to zero during training. This forces the model to learn more robust features.\n",
    "<br> The details provided for this fase are: <br>`(drop): Dropout(p=0.1, inplace=False)` <br> From this details we can learn: <br> - dropout happens to 10% of elements<br> - a new vector is generated instead of replace values of the existing vector inplace=False<br>\n",
    "So, during training, for each embedding vector in the input matrix 10% of the elements are randomly choose and set to 0. All remaining values are increase to maintaing the expectec sum value. During inference the dropout is disabled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a177ac-a3a5-4713-b920-265401df40df",
   "metadata": {},
   "source": [
    "### Transformation Block\n",
    "In this part we have the tranformers architecture. <br> The details provided for this fase are: <br>`(0-5): 6 x GPT2Block(` <br> It means that there are 6 transformation blocks with same architecture called GPT2Block index from 0 to 5. Now <br> \n",
    "#### Normalization Layer 1 (ln_1)\n",
    "<br> The first layer is a normalization layer and its details are: <br> `(ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)`<br> It means:<br> - The normalization is applied to all 768 elements of each embedding <br> - A small constant is added to denominator (1e-5) to avoid division by zero<br> - the element wise affine enables and advanced normalization (z-score) technique that apply gama (proportional) and beta (constant) parameters to the output of basic normalization. Both gamma and betta are learned along the training process so it allows the normalization to adapt to the data.<br> By normalizing the inputs to the transformer block, it ensures that the activations remain well-behaved, which is crucial for the stability of deep networks like GPT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "480ab41b-d8e6-43d4-9923-92179ae2f82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LayerNorm input: (tensor([[[ 0.0465, -0.3070,  0.1146,  ..., -0.1315,  0.1570,  0.0658],\n",
      "         [ 0.0893, -0.1634,  0.0157,  ..., -0.0543,  0.1389,  0.0112],\n",
      "         [ 0.0128, -0.0856,  0.0601,  ...,  0.0681, -0.0544, -0.0850],\n",
      "         [ 0.0711,  0.0562,  0.2187,  ...,  0.1322,  0.0143,  0.0475],\n",
      "         [-0.0564, -0.1722,  0.2268,  ..., -0.0830,  0.2066,  0.0936],\n",
      "         [-0.1349, -0.0794,  0.1355,  ..., -0.1464,  0.0255,  0.0916]]]),)\n",
      "\n",
      "LayerNorm output: tensor([[[ 0.0344, -0.1351,  0.0305,  ..., -0.0629,  0.0545,  0.0270],\n",
      "         [ 0.0923, -0.1218, -0.0079,  ..., -0.0457,  0.0874,  0.0023],\n",
      "         [ 0.0214, -0.0658,  0.0307,  ...,  0.0636, -0.0639, -0.0840],\n",
      "         [ 0.0919,  0.0721,  0.1640,  ...,  0.1291, -0.0011,  0.0431],\n",
      "         [-0.0565, -0.1489,  0.1654,  ..., -0.0777,  0.1644,  0.0825],\n",
      "         [-0.1509, -0.0637,  0.0963,  ..., -0.1427,  0.0067,  0.0842]]])\n"
     ]
    }
   ],
   "source": [
    "# Set model to evaluation mode (disable dropout for consistency)\n",
    "model.eval()\n",
    "\n",
    "# Register a forward hook to capture the LayerNorm output from the first block (block 0)\n",
    "def hook(module, hook_input, output):\n",
    "    print(\"LayerNorm input:\", hook_input)\n",
    "    print(\"\\nLayerNorm output:\", output)\n",
    "\n",
    "# Attach the hook to the ln_1 of the first GPT2Block (index 0)\n",
    "hook_handle = model.transformer.h[0].ln_1.register_forward_hook(hook)\n",
    "\n",
    "# Forward pass through the model\n",
    "with torch.no_grad():  # Disable gradient computation for efficiency\n",
    "    outputs = model(tokens['input_ids'])\n",
    "\n",
    "# Remove the hook after use\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea22c803-d9a0-460d-b285-e0b6e37c01de",
   "metadata": {},
   "source": [
    "#### Attention Layer\n",
    "This layer implements the self-attention mechanism, a core part of the transformer architecture. The layer is responsible for allowing the model to focus on different parts of the input sequence when processing each token.<br>\n",
    "Let's see it in details:<br>\n",
    "`(attn): GPT2Attention(`<br>\n",
    "`    (c_attn): Conv1D(nf=2304, nx=768)`<br>\n",
    "`    (c_proj): Conv1D(nf=768, nx=768)`<br>\n",
    "`    (attn_dropout): Dropout(p=0.1, inplace=False)`<br>\n",
    "`    (resid_dropout): Dropout(p=0.1, inplace=False)`<br>\n",
    "`)`<br>\n",
    " - `(c_attn): Conv1D(nf=2304, nx=768)`: A 1D convolution layer that projects the input into query, key, and value vectors. A convolution kernel is applied to each token vector and, as result of the convolution, 3 vectors a created Query (Q), Key (K) and Value (V). This is an Attention Component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "267e160d-af01-4ce0-acb5-bc78672ac3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention output: (tensor([[[-0.0570,  0.1594, -0.4522,  ...,  0.0009,  0.0534,  0.0127],\n",
      "         [-0.4796,  0.6074, -0.7725,  ..., -0.0054,  0.0342, -0.0250],\n",
      "         [ 0.5455,  0.3538, -0.5408,  ...,  0.0220,  0.0340,  0.0448],\n",
      "         [-0.0961,  0.2955, -0.3571,  ...,  0.0276,  0.0669,  0.0506],\n",
      "         [ 0.8775,  0.3109, -0.1867,  ..., -0.0256,  0.0185,  0.0135],\n",
      "         [ 0.8812, -0.3464,  0.3855,  ...,  0.0118,  0.0187,  0.0869]]]), None)\n"
     ]
    }
   ],
   "source": [
    "def hook2(module, hook_input, output):\n",
    "    #print(\"Attention output shape:\", output.shape)\n",
    "    print(\"Attention output:\", output)\n",
    "\n",
    "# Attach hook to the attn layer of the first block\n",
    "hook_handle = model.transformer.h[0].attn.register_forward_hook(hook2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model(tokens['input_ids'])\n",
    "\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0641ec3-6fbe-479e-a77f-6d64ba9fe0b9",
   "metadata": {},
   "source": [
    "- `(c_proj): Conv1D(nf=768, nx=768)`: A new kernel is applied to the result of (c_attn) and a vector with dimension 768 is generated as result. Returning it back to original dimesion. This is an Projection Component.<br> Rhe (c_proj) layer allows the model to learn a separate transformation for the attention output, which can help adjust the scale, emphasize certain features, or align the output with the input dimension for the residual connection (where the c_proj output is added to the input of the block).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3b5fbf9-2fa8-4daa-a9a7-e527f2ba178a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_proj output shape: torch.Size([1, 6, 768])\n",
      "c_proj output: tensor([[[-0.0570,  0.1594, -0.4522,  ...,  0.0009,  0.0534,  0.0127],\n",
      "         [-0.4796,  0.6074, -0.7725,  ..., -0.0054,  0.0342, -0.0250],\n",
      "         [ 0.5455,  0.3538, -0.5408,  ...,  0.0220,  0.0340,  0.0448],\n",
      "         [-0.0961,  0.2955, -0.3571,  ...,  0.0276,  0.0669,  0.0506],\n",
      "         [ 0.8775,  0.3109, -0.1867,  ..., -0.0256,  0.0185,  0.0135],\n",
      "         [ 0.8812, -0.3464,  0.3855,  ...,  0.0118,  0.0187,  0.0869]]])\n"
     ]
    }
   ],
   "source": [
    "def hook3(module, hook_input, output):\n",
    "    print(\"c_proj output shape:\", output.shape)\n",
    "    print(\"c_proj output:\", output)\n",
    "\n",
    "hook_handle = model.transformer.h[0].attn.c_proj.register_forward_hook(hook3)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model(tokens['input_ids'])\n",
    "\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff3b5c2-a176-4589-a930-2b5673ca6eca",
   "metadata": {},
   "source": [
    "- `(attn_dropout): Dropout(p=0.1, inplace=False)`: This dropout is applied to the attention weights before they are used to compute the weighted sum of the value vectors (i.e., after the softmax((QK^T)/√d_k) step but before multiplying by V). It regularizes the attention mechanism by randomly setting 10% of the attention weight values to zero during training. This prevents the model from relying too heavily on any single attention relationship between tokens, encouraging more robust feature learning.<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " - `(resid_dropout): Dropout(p=0.1, inplace=False)`: This dropout is applied to the output of c_proj (the projected attention output, shape (batch_size, seq_len, 768) after the attention computation and projection but before the residual connection is added. It regularizes the final output of the attention block by randomly setting 10% of the elements in the 768-dimensional vectors to zero during training. This helps prevent overfitting by introducing noise and ensuring the model doesn’t depend too much on specific features in the attention output.<br>\n",
    "\n",
    "It completes the Attention Module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407c761c-bc54-4eb9-8e22-5754905d1fc2",
   "metadata": {},
   "source": [
    "#### Normalization Layer 2 (ln_2)\n",
    "- `(ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)`: Other normalization layer. The (ln_2) layer is applied after the residual connection, where the output of the GPT2Attention module (after resid_dropout) is added to the input of the block (the output of the initial ln_1 and dropout). This normalized output is then fed into the feed-forward network (MLP) within the GPT2Block.<br> Like ln_1, ln_2 performs layer normalization to stabilize and accelerate training by normalizing the input across the 768 feature dimensions for each token. It ensures that the combined output from the attention block and residual connection has consistent statistical properties, which is crucial before passing it to the non-linear feed-forward layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9d08c0c-e78a-4373-8c2e-3ed17dd8bc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln_2 output shape: torch.Size([1, 6, 768])\n",
      "ln_2 output: tensor([[[ 3.8605e-02,  3.3201e-02, -4.4046e-02,  ..., -1.4648e-01,\n",
      "           2.3323e-01,  7.9626e-02],\n",
      "         [-1.4356e-04,  1.2792e-01, -1.0325e-01,  ..., -7.9846e-02,\n",
      "           1.5782e-01, -1.1437e-02],\n",
      "         [ 9.1684e-02,  9.8509e-02, -6.1494e-02,  ...,  4.9615e-02,\n",
      "          -1.8802e-02, -3.6460e-02],\n",
      "         [ 3.4916e-02,  1.1486e-01, -1.0481e-02,  ...,  1.2145e-01,\n",
      "           7.4712e-02,  7.1423e-02],\n",
      "         [ 1.2014e-01,  7.8262e-02,  1.7161e-02,  ..., -1.3898e-01,\n",
      "           1.9977e-01,  7.3096e-02],\n",
      "         [ 1.1336e-01, -1.3552e-02,  9.4564e-02,  ..., -1.5752e-01,\n",
      "           4.1171e-02,  1.3407e-01]]])\n"
     ]
    }
   ],
   "source": [
    "def hook4(module, hook_input, output):\n",
    "    print(\"ln_2 output shape:\", output.shape)\n",
    "    print(\"ln_2 output:\", output)\n",
    "\n",
    "# Attach hook to the ln_2 layer of the first block\n",
    "hook_handle = model.transformer.h[0].ln_2.register_forward_hook(hook4)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model(tokens['input_ids'])\n",
    "\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4e9ac7-aac3-446f-a63a-91d170964e97",
   "metadata": {},
   "source": [
    "#### Feed-Forward Network (MLP)\n",
    "This layer represents the feed-forward network (FFN) within each transformer block, applying a non-linear transformation to the data. Let's check it: <br>\n",
    "`(mlp): GPT2MLP(`<br>\n",
    "`      (c_fc): Conv1D(nf=3072, nx=768)`<br>\n",
    "`      (c_proj): Conv1D(nf=768, nx=3072)`<br>\n",
    "`      (act): NewGELUActivation()`<br>\n",
    "`      (dropout): Dropout(p=0.1, inplace=False)`<br>\n",
    "`)`<br>\n",
    "<br>\n",
    " - `(c_fc): Conv1D(nf=3072, nx=768)`: A 1D convolution layer that expands the 768-dimensional input to a 3072-dimensional intermediate representation.The input from ln_2 (shape batch_size, seq_len, 768) is fed into c_fc, which uses a Conv1D with nf=3072 and nx=768."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fc873c8-9202-4b9e-b54d-ca23b847b689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_fc output shape: torch.Size([1, 6, 3072])\n",
      "c_fc output: tensor([[[ 0.5976, -0.3890, -0.7655,  ..., -2.8732, -1.8182,  0.6358],\n",
      "         [ 0.8803,  0.5737,  0.1588,  ..., -1.5404, -0.9705,  0.1162],\n",
      "         [ 0.7707, -0.6079, -0.6141,  ..., -1.4422, -0.8109,  0.3963],\n",
      "         [ 0.5312, -0.1843, -0.6936,  ..., -1.0675, -0.8499,  0.4928],\n",
      "         [ 0.9267, -0.0587, -0.0083,  ..., -1.5407, -0.3576, -0.7753],\n",
      "         [ 0.6779, -0.7721,  0.0674,  ..., -2.0618, -0.8126,  0.4597]]])\n"
     ]
    }
   ],
   "source": [
    "def hook5(module, hook_input, output):\n",
    "    print(\"c_fc output shape:\", output.shape)\n",
    "    print(\"c_fc output:\", output)\n",
    "\n",
    "# Attach hook to the ln_2 layer of the first block\n",
    "hook_handle = model.transformer.h[0].mlp.c_fc.register_forward_hook(hook5)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model(tokens['input_ids'])\n",
    "\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1604c5dc-9415-4713-b8a8-2b8f75421d3d",
   "metadata": {},
   "source": [
    " - `(act): NewGELUActivation()`: Non-linear Activation with NewGELUActivation. The 3072-dimensional output from c_fc is passed through the NewGELUActivation function, a modified Gaussian Error Linear Unit (GELU) activation. GELU introduces non-linearity and is defined as: `GELU(x)=x⋅Φ(x)` where Φ(x) is the cumulative distribution function of the standard normal distribution. The \"NewGELU\" variant (used in GPT-2) is an approximation for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d3d897b-d5d9-4e16-b808-c53385fd16ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act output shape: torch.Size([1, 6, 3072])\n",
      "act output: tensor([[[ 0.4332, -0.1356, -0.1700,  ..., -0.0054, -0.0628,  0.4689],\n",
      "         [ 0.7135,  0.4113,  0.0894,  ..., -0.0953, -0.1611,  0.0635],\n",
      "         [ 0.6007, -0.1652, -0.1656,  ..., -0.1079, -0.1693,  0.2592],\n",
      "         [ 0.3731, -0.0787, -0.1693,  ..., -0.1527, -0.1681,  0.3395],\n",
      "         [ 0.7625, -0.0280, -0.0041,  ..., -0.0953, -0.1288, -0.1699],\n",
      "         [ 0.5091, -0.1700,  0.0355,  ..., -0.0403, -0.1693,  0.3113]]])\n"
     ]
    }
   ],
   "source": [
    "def hook6(module, hook_input, output):\n",
    "    print(\"act output shape:\", output.shape)\n",
    "    print(\"act output:\", output)\n",
    "\n",
    "# Attach hook to the ln_2 layer of the first block\n",
    "hook_handle = model.transformer.h[0].mlp.act.register_forward_hook(hook6)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model(tokens['input_ids'])\n",
    "\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ccb1a8-c762-45e0-bc67-9a0740f57723",
   "metadata": {},
   "source": [
    " - `(c_proj): Conv1D(nf=768, nx=3072)`: The activated 3072-dimensional vector is then projected back to 768 dimensions using c_proj (nf=768, nx=3072). The weight matrix size is 3072×768×1=2,359,2963072 \\times 768 \\times 1 = 2,359,2963072 \\times 768 \\times 1 = 2,359,296\n",
    " (plus 768 bias terms if included, totaling 2,360,064 parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e415fb4-2315-41e9-aa94-9b614449a94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c_proj output shape: torch.Size([1, 6, 3072])\n",
      "c_proj output: tensor([[[ 0.4332, -0.1356, -0.1700,  ..., -0.0054, -0.0628,  0.4689],\n",
      "         [ 0.7135,  0.4113,  0.0894,  ..., -0.0953, -0.1611,  0.0635],\n",
      "         [ 0.6007, -0.1652, -0.1656,  ..., -0.1079, -0.1693,  0.2592],\n",
      "         [ 0.3731, -0.0787, -0.1693,  ..., -0.1527, -0.1681,  0.3395],\n",
      "         [ 0.7625, -0.0280, -0.0041,  ..., -0.0953, -0.1288, -0.1699],\n",
      "         [ 0.5091, -0.1700,  0.0355,  ..., -0.0403, -0.1693,  0.3113]]])\n"
     ]
    }
   ],
   "source": [
    "def hook7(module, hook_input, output):\n",
    "    print(\"c_proj output shape:\", output.shape)\n",
    "    print(\"c_proj output:\", output)\n",
    "\n",
    "# Attach hook to the ln_2 layer of the first block\n",
    "hook_handle = model.transformer.h[0].mlp.act.register_forward_hook(hook7)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model(tokens['input_ids'])\n",
    "\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bbedb7-f1cd-4e27-8348-51dc557c46d4",
   "metadata": {},
   "source": [
    " - `(dropout): Dropout(p=0.1, inplace=False)`: A dropout layer with p=0.1 is applied to the 768-dimensional output, randomly setting 10% of the elements to zero during training. This regularizes the MLP output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f212eec2-ef94-4d92-853a-f98352d2b1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2MLP output shape: torch.Size([1, 6, 768])\n",
      "GPT2MLP output: tensor([[[-0.5530, -0.2582, -1.3098,  ..., -1.5001, -0.3564, -1.5608],\n",
      "         [-1.4469,  0.3642, -1.3667,  ..., -0.5334,  0.1527, -2.2635],\n",
      "         [-0.6052, -0.2670, -0.3868,  ...,  0.7127,  0.1794,  0.4032],\n",
      "         [-0.1885,  0.0130,  0.5213,  ...,  0.0481,  0.6167, -0.6835],\n",
      "         [-0.4523,  0.1644, -0.0204,  ..., -0.6527, -1.7580, -1.2175],\n",
      "         [ 0.2289, -0.7968,  0.2175,  ..., -1.0243,  0.3720,  0.5569]]])\n"
     ]
    }
   ],
   "source": [
    "def hook8(module, hook_input, output):\n",
    "    print(\"GPT2MLP output shape:\", output.shape)\n",
    "    print(\"GPT2MLP output:\", output)\n",
    "\n",
    "# Attach hook to the mlp layer of the first block\n",
    "hook_handle = model.transformer.h[0].mlp.register_forward_hook(hook8)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model(tokens['input_ids'])\n",
    "\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf46d856-8b09-424c-8fd1-62cb98f43dff",
   "metadata": {},
   "source": [
    "Exectuion order of steps is different form order shown in model details.<br>\n",
    "Execution order in the GPT2BlockInput:<br>\n",
    "ln_1 → GPT2Attention → Residual Connection → ln_2 → GPT2MLP → Residual Connection → Output. <br>\n",
    "ln_2 output → c_fc → NewGELUActivation → c_proj → dropout → Residual Addition.<br>\n",
    "<br>\n",
    "You can understand the execution order inspecting source code. There is a foward method.<br>\n",
    "```\n",
    "def forward(self, x):\n",
    "    hidden_states = self.c_fc(x)         # Project to 3072\n",
    "    hidden_states = self.act(hidden_states)  # Apply activation\n",
    "    hidden_states = self.c_proj(hidden_states)  # Project back to 768\n",
    "    hidden_states = self.dropout(hidden_states)  # Apply dropout\n",
    "    return hidden_states\n",
    "```\n",
    "\n",
    "Or you can inspect a foward pass, like the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da676422-d89e-49e9-9e7d-c6838c35145a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: c_fc, Input shape: torch.Size([1, 6, 768]), Output shape: torch.Size([1, 6, 3072])\n",
      "Processed: act, Input shape: torch.Size([1, 6, 3072]), Output shape: torch.Size([1, 6, 3072])\n",
      "Processed: c_proj, Input shape: torch.Size([1, 6, 3072]), Output shape: torch.Size([1, 6, 768])\n",
      "Processed: dropout, Input shape: torch.Size([1, 6, 768]), Output shape: torch.Size([1, 6, 768])\n",
      "Execution order: ['c_fc', 'act', 'c_proj', 'dropout']\n"
     ]
    }
   ],
   "source": [
    "# code to read exection order from model execution\n",
    "\n",
    "# Dictionary to store the order of layer execution\n",
    "execution_order = []\n",
    "hooks_handles = []\n",
    "\n",
    "# Hook function to record the order\n",
    "def hook9(module, hook_input, output, layer_name):\n",
    "    execution_order.append(layer_name)\n",
    "    print(f\"Processed: {layer_name}, Input shape: {hook_input[0].shape}, Output shape: {output.shape}\")\n",
    "\n",
    "# Attach hooks to each layer in the first block's MLP\n",
    "mlp = model.transformer.h[0].mlp\n",
    "for name, module in mlp.named_children():\n",
    "    handle = module.register_forward_hook(lambda m, i, o, n=name: hook9(m, i, o, n))\n",
    "    hooks_handles.append(handle)\n",
    "\n",
    "# Create a sample input\n",
    "with torch.no_grad():\n",
    "    model(tokens['input_ids'])\n",
    "\n",
    "# Print the execution order\n",
    "print(\"Execution order:\", execution_order)\n",
    "\n",
    "# remove hooks to each layer in the first block's MLP\n",
    "for hook in hooks_handles:\n",
    "    hook.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180cdbb3-2300-4b53-90e1-ce88b885e93f",
   "metadata": {},
   "source": [
    "### Final Normalization\n",
    "The ln_f layer is applied to the output of the last GPT2Block (after the residual connection of the MLP in the sixth block). This normalized output is then passed to the (lm_head) layer for the final language modeling prediction.<br>\n",
    "This layer normalizes the 768-dimensional embedding vectors across the feature dimension for each token in the sequence, ensuring the output is well-conditioned before the linear transformation to the vocabulary size (50257 in this case). It helps stabilize the final representation and prepares it for the prediction task (e.g., next token prediction).<br>\n",
    "\n",
    "`(ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1aeb757a-a3a4-4628-abef-73087cff4467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln_f output shape: torch.Size([1, 6, 768])\n",
      "ln_f output: tensor([[[-2.5024e-02,  3.6233e-01, -1.1136e-01,  ..., -1.8130e-01,\n",
      "           1.1482e-01, -1.8825e-01],\n",
      "         [-1.7677e-01,  9.3993e-02, -1.9730e-01,  ..., -2.3405e-01,\n",
      "           5.3724e-01, -2.4905e-01],\n",
      "         [ 1.9197e-01, -3.7879e-02,  1.3627e-02,  ...,  2.1321e-02,\n",
      "           1.8326e-01,  3.5414e-03],\n",
      "         [ 6.2068e-01,  3.8346e-01,  8.5196e-01,  ..., -2.4001e-02,\n",
      "           3.8335e-01, -4.9142e-01],\n",
      "         [ 1.4832e-01,  1.2018e-01,  7.5178e-02,  ..., -7.7200e-02,\n",
      "          -1.6340e-01, -5.0223e-04],\n",
      "         [ 3.6321e-02, -1.6660e-01, -4.7713e-02,  ..., -2.3693e-02,\n",
      "          -1.2833e-01,  5.3685e-02]]])\n"
     ]
    }
   ],
   "source": [
    "# Hook function to capture the output\n",
    "def hook10(module, hook_input, output):\n",
    "    print(\"ln_f output shape:\", output.shape)\n",
    "    print(\"ln_f output:\", output)\n",
    "\n",
    "# Attach hook to the ln_f layer\n",
    "hook_handle = model.transformer.ln_f.register_forward_hook(hook10)\n",
    "\n",
    "# Create a sample input\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens['input_ids'])\n",
    "\n",
    "# Remove the hook\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03942445-fe92-4cb5-bd33-99ddc33db85a",
   "metadata": {},
   "source": [
    "### Final Normalization\n",
    "The final layer in the DistilGPT2 model after the (ln_f) normalization. The lm_head layer takes the normalized output from ln_f (shape [batch_size, seq_len, 768]) and produces the final output of the model, which is a set of logits for language modeling. This layer is applied after the transformer stack to map the hidden states to the vocabulary space.<br>\n",
    "It transforms the 768-dimensional hidden representations of each token into a probability distribution over the 50,257-token vocabulary, enabling the model to predict the next token in a sequence (e.g., for autoregressive tasks like text generation).<br>\n",
    "\n",
    "`(lm_head): Linear(in_features=768, out_features=50257, bias=False)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec2edab9-fb89-488a-b30e-8d13900ef468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_head output shape: torch.Size([1, 6, 50257])\n",
      "lm_head output (first few logits):\n",
      " tensor([[[-32.7786, -31.2604, -33.4580, -33.3068, -33.5693],\n",
      "         [-41.9481, -47.0836, -48.3396, -48.4019, -47.3441],\n",
      "         [-57.8325, -60.0321, -60.2201, -59.9341, -60.7340],\n",
      "         [-46.5706, -48.6622, -49.4792, -48.8984, -47.7866],\n",
      "         [-54.2288, -58.9350, -62.3507, -63.2325, -62.3509],\n",
      "         [-64.1996, -66.1278, -66.1443, -66.4251, -67.9091]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Hook function to capture the output\n",
    "def hook11(module, hook_input, output):\n",
    "    print(\"lm_head output shape:\", output.shape)\n",
    "    print(\"lm_head output (first few logits):\\n\", output[:, :, :5]) \n",
    "\n",
    "# Attach hook to the lm_head layer\n",
    "hook_handle = model.lm_head.register_forward_hook(hook11)\n",
    "\n",
    "# Create a sample input\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens['input_ids'])\n",
    "\n",
    "# Remove the hook\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b412c998-6944-426b-a004-2c11a7bc37d6",
   "metadata": {},
   "source": [
    "The (lm_head) layer produces a tensor of shape (batch_size, seq_len, 50257), where each element is a logit. These logits are unnormalized scores (raw numbers) representing the model’s preference for each of the 50,257 tokens in the vocabulary at each position in the sequence.<br>\n",
    "The logits are not probabilities. To convert them into a probability distribution, you need to apply a softmax function over the vocabulary dimension (axis 2) for each token position. The softmax normalizes the logits into values between 0 and 1 that sum to 1, interpretable as probabilities.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28a1c461-9b9b-41a9-850a-4892404c2086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for the last token (first 10): tensor([3.4514e-04, 5.0186e-05, 4.9366e-05, 3.7278e-05, 8.4521e-06, 7.9013e-06,\n",
      "        4.9008e-05, 1.5883e-04, 2.4542e-05, 1.6336e-04])\n"
     ]
    }
   ],
   "source": [
    "# using output from previous execution\n",
    "logits = outputs.logits\n",
    "\n",
    "# Convert logits to probabilities\n",
    "probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "# Print probabilities for the last token\n",
    "last_token_probs = probabilities[0, -1, :]  # Shape: [50257]\n",
    "print(\"Probabilities for the last token (first 10):\", last_token_probs[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e1285-ef03-4315-bcbc-870130c2a1bf",
   "metadata": {},
   "source": [
    "To determine the next token, you need to identify the token with the highest probability (or sample from the distribution, depending on the strategy). Ordering the probabilities helps you rank the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c165753e-1a89-4b72-9359-c968749829a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most likely next token: \n",
      "\n",
      "Top 5 next tokens and probabilities: [('\\n', 0.40251022577285767), (' I', 0.11191854625940323), (' You', 0.021729281172156334), (' My', 0.018897606059908867), ('<|endoftext|>', 0.016403187066316605)]\n"
     ]
    }
   ],
   "source": [
    "# Get the index of the most likely token (greedy decoding)\n",
    "next_token_id = torch.argmax(last_token_probs).item()\n",
    "next_token = tokenizer.decode(next_token_id)\n",
    "print(f\"Most likely next token: {next_token}\")\n",
    "\n",
    "# Get top 5 tokens\n",
    "top_k_values, top_k_indices = torch.topk(last_token_probs, k=5)\n",
    "top_tokens = [tokenizer.decode(idx.item()) for idx in top_k_indices]\n",
    "print(f\"Top 5 next tokens and probabilities: {list(zip(top_tokens, top_k_values.tolist()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ccba7254-a4f4-442c-82fc-39f921de721c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The, I name,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = ''\n",
    "\n",
    "for logit in probabilities[0]:\n",
    "    next_token_id = torch.argmax(logit).item()\n",
    "    next_token = tokenizer.decode(next_token_id)\n",
    "    #print(f'next token is: {next_token}')\n",
    "    response = response + next_token\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bd8a22-0db2-4cb3-8857-e75df058c2c5",
   "metadata": {},
   "source": [
    "A few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5781e6fe-eb6c-4d5a-b383-e00dac41d4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6483578d-01db-4156-a63b-a03c8ee5a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recursive(input_ids, model, current_length = 0, max_tokens = 20, end_token_id = 50256):\n",
    "    # Base cases: reached max_tokens or generated end token\n",
    "    if current_length >= max_tokens:\n",
    "        return input_ids\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        outputs = model(input_ids)\n",
    "        logits = outputs.logits[:, -1, :]  # Get logits for the last token\n",
    "        probabilities = torch.softmax(logits, dim=-1)\n",
    "        next_token_id = torch.argmax(probabilities, dim=-1).unsqueeze(0)  # Greedy decoding\n",
    "\n",
    "        # Check if end token is generated\n",
    "        if next_token_id.item() == end_token_id:\n",
    "            return torch.cat([input_ids, next_token_id], dim=-1)\n",
    "\n",
    "        # Recursive call with updated input\n",
    "        new_input_ids = torch.cat([input_ids, next_token_id], dim=-1)\n",
    "        return generate_recursive(new_input_ids, model, current_length + 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e9019df-c929-4a28-bafd-798afef98f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(messages, model, tokenizer):\n",
    "    input_ids = tokenizer.encode(messages, return_tensors=\"pt\")\n",
    "    generated_ids = generate_recursive(input_ids, model)\n",
    "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=False)\n",
    "    return generated_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "00bfa573-4c75-42e4-bcea-cd85c3d740a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my friend. How you doing?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message = \"Hello, my friend. How you doing?\"\n",
    "\n",
    "print(generate_text(message, model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2ae6227-bf66-439e-8ec8-7260a66382ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My favorite color is the red. I love the color of the red. I love the color of the red. I\n"
     ]
    }
   ],
   "source": [
    "message = \"My favorite color is\"\n",
    "\n",
    "print(generate_text(message, model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9fbd87bb-b711-4b5f-81e9-a18dc39f938f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cats are iced with a little bit of salt.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message = \"Cats are \"\n",
    "\n",
    "print(generate_text(message, model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d01cff98-2f0f-4fbb-bffa-00121c818c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eu falo portugues ia falo portugues ia falo portugues ia falo portugues\n"
     ]
    }
   ],
   "source": [
    "message = \"Eu falo portugues \"\n",
    "\n",
    "print(generate_text(message, model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "829171e4-132f-4feb-a442-c9de15bd9fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palmeiras não tem été de la vida de la vida de la vida de la vida de la\n"
     ]
    }
   ],
   "source": [
    "message = \"Palmeiras não tem \"\n",
    "\n",
    "print(generate_text(message, model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051cce68-b966-49c6-84f9-5ea2daf514ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
